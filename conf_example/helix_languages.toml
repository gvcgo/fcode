##############################
## Configuration for lsp-ai ##
##############################

[language-server.lsp-ai]
command = "lsp-ai"

[language-server.markdown-oxide]
command = "markdown-oxide"
args = ["server"]

[language-server.protols]
command = "protols"
args = ["--include-paths", "proto/src"]

[language-server.lsp-ai.config.memory]
file_store = { }

[language-server.lsp-ai.config.models.model1]
type = "open_ai"
chat_endpoint = "http://127.0.0.1:8123/v1/completions"
model =  "LongCat-Flash-Chat"
auth_token_env_var_name = "LONGCAT_API_KEY"

[language-server.lsp-ai.config.completion]
model = "model1"

[language-server.lsp-ai.config.completion.parameters]
max_tokens = 64
max_context = 1024

## Configure the messages per your needs
[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "system"
content = "Instructions:\n- You are an AI programming assistant.\n- Given a piece of code with the cursor location marked by \"<CURSOR>\", replace \"<CURSOR>\" with the correct code or comment.\n- First, think step-by-step.\n- Describe your plan for what to build in pseudocode, written out in great detail.\n- Then output the code replacing the \"<CURSOR>\"\n- Ensure that your completion fits within the language context of the provided code snippet (e.g., Python, JavaScript, Rust).\n\nRules:\n- Only respond with code or comments.\n- Only replace \"<CURSOR>\"; do not include any previously written code.\n- Never include \"<CURSOR>\" in your response\n- If the cursor is within a comment, complete the comment meaningfully.\n- Handle ambiguous cases by providing the most contextually appropriate completion.\n- Be consistent with your responses."

[[language-server.lsp-ai.config.completion.parameters.messages]]
  role = "user"
  content = "Complete the code at the cursor. Use the surrounding file context and project context as necessary. Replace <CURSOR> with the completed text. Current code: {CODE}\nProject context: {CONTEXT}"

[[language-server.lsp-ai.config.chat]]
trigger = "!C"
action_display_name = "Chat"
model = "model1"

[language-server.lsp-ai.config.chat.parameters]
max_context = 4096
max_tokens = 1024
system = "You are a code assistant chatbot. The user will ask you for assistance coding and you will do you best to answer succinctly and accurately"

### yaml
[language-server.yaml-language-server]
command = "yaml-language-server"
args = ["--stdio"]

[language-server.yaml-language-server.config]
format = { enable = true }
validation = true

[language-server.yaml-language-server.config.schemas]
"https://json.schemastore.org/github-workflow.json" = ".github/workflows/*.{yml,yaml}"
"https://raw.githubusercontent.com/ansible-community/schemas/main/f/ansible-tasks.json" = "roles/{tasks,handlers}/*.{yml,yaml}"


#################################
## Configuration for languages ##
#################################

[[language]]
name = "go"
language-servers = ["gopls", "lsp-ai"]

[[language]]
name = "toml"
language-servers = ["lsp-ai"]

[[language]]
name = "yaml"
file-types = ["yaml", "yml"]
language-servers = ["yaml-language-server", "lsp-ai"]

[[language]]
name = "markdown"
file-types = ["md", "markdown"]
language-servers = ["markdown-oxide", "lsp-ai"]

[[language]]
name = "protobuf"
language-servers = ["protols", "lsp-ai"]

